{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72af5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import copy\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9facc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_delim_auto(filepath):\n",
    "    \"\"\"\n",
    "    Automatically read .tsv, .csv, .tsv.gz, or .csv.gz based on extension.\n",
    "    \"\"\"\n",
    "    filepath = str(filepath)\n",
    "    if filepath.endswith(\".tsv\") or filepath.endswith(\".tsv.gz\"):\n",
    "        return pd.read_csv(filepath, sep=\"\\t\", compression=\"infer\")\n",
    "    elif filepath.endswith(\".csv\") or filepath.endswith(\".csv.gz\"):\n",
    "        return pd.read_csv(filepath, sep=\",\", compression=\"infer\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193408c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonise_and_format(\n",
    "    sumstat,\n",
    "    bim_file,\n",
    "    has_rsid=True,\n",
    "    n_cases=None,\n",
    "    n_controls=None,\n",
    "    rs_id = 'SNP',effect_allele = 'effect_allele',other_allele ='other_allele', eaf = 'effect_allele_frequency',\n",
    "    beta = 'beta',se = 'standard_error',bp = 'base_pair_location',chromosome='chromosome',pval ='p_value'\n",
    "):\n",
    "   \n",
    "    df = read_delim_auto(sumstat)\n",
    "    df = df.copy()\n",
    " \n",
    "    # Step 1: Rename SNP column for merge\n",
    "    if has_rsid:\n",
    "        df = df.rename(columns={rs_id: 'ID'})\n",
    "        merged = bim_file.merge(df, on='ID')\n",
    "    else:\n",
    "        df['chr_pos'] = df[chromosome].astype(str) + '_' + df[bp].astype(str)\n",
    "        merged = bim_file.merge(df, on='chr_pos')\n",
    "\n",
    "    # Step 2: Harmonisation \n",
    "    # Adopted from https://github.com/zhwm/sharepro_coloc_analysis\n",
    "    \n",
    "    merged[effect_allele]= merged[effect_allele].str.upper()\n",
    "    merged[other_allele]= merged[other_allele].str.upper()\n",
    "    def assign_maf_beta(row):\n",
    "        ea, oa = row[effect_allele], row[other_allele]\n",
    "        alt, ref = row['ALT'], row['REF']\n",
    "        eaf_val, beta_val = row[eaf], row[beta]\n",
    "        if (ea, oa) == (alt, ref):\n",
    "            return eaf_val, beta_val\n",
    "        elif (ea, oa) == (ref, alt):\n",
    "            return 1 - eaf_val, -beta_val\n",
    "        else:\n",
    "            return pd.NA, pd.NA\n",
    "\n",
    "    merged[['eaf_temp', 'beta_temp']] = merged.apply(assign_maf_beta, axis=1, result_type='expand')\n",
    "    merged['EAF'] = merged['eaf_temp']\n",
    "    merged['BETA'] = merged['beta_temp']\n",
    "    merged.drop(columns=['eaf_temp', 'beta_temp'], inplace=True)\n",
    "\n",
    "    # Step 3: Add effective sample size\n",
    "    if n_cases and n_controls:\n",
    "        n_eff = round(4 / ((1 / n_cases) + (1 / n_controls)))\n",
    "        merged['N'] = n_eff\n",
    "\n",
    "    # Step 4: Rename columns using col_map\n",
    "    renaming = {'ID':'SNP','ALT':'A1','REF':'A2',se:'SE',pval:'P'}\n",
    "    merged = merged.rename(columns=renaming)\n",
    "\n",
    "    selected_cols = ['SNP', 'A1', 'A2', 'EAF', 'BETA', 'SE', 'P', 'N']\n",
    "\n",
    "    return merged[selected_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699115c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bim_dict(bimdir):\n",
    "    # get bim, addopted from https://github.com/zhwm/sharepro_coloc_analysis\n",
    "    bim_dict = {}\n",
    "    bim_dup = []\n",
    "    with open(bimdir) as bim:\n",
    "        for line in bim:\n",
    "            ll = line.strip().split()\n",
    "            if ll[1] in bim_dict:\n",
    "                bim_dup.append(ll[1])\n",
    "            else:\n",
    "                bim_dict[ll[1]]=(ll[1], ll[4], ll[5])\n",
    "    # remove dups\n",
    "    for drs in bim_dup:\n",
    "        del bim_dict[drs]\n",
    "    return bim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f108df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bim_dic = get_bim_dict('/Users/a1/projects/IL6_pertrubation_coloc/sharepro_analysis/region_chr7_22466819_23071617.bim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ca717a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read exposure data\n",
    "il6 = pd.read_table('../summ_stats/35459240-GCST90029070-EFO_0004458-Build37.f.tsv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9fa470",
   "metadata": {},
   "outputs": [],
   "source": [
    "il6 = il6.drop(['odds_ratio','ci_lower','ci_upper','effect_allele_frequency'], axis =1) # empty \n",
    "il6 = il6[il6.chromosome ==7]\n",
    "il6 = il6.dropna()\n",
    "il6 = il6.rename ( columns = {'variant_id':'ID'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32d816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fill the eaf for IL6\n",
    "frq_data = pd.read_table('../sharepro_analysis/region_chr7_22466819_23071617.afreq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b54c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "il6['alt_bim'] = il6['ID'].map(lambda x: bim_dic.get(x, (None,None,None))[1])\n",
    "il6['ref_bim'] = il6['ID'].map(lambda x: bim_dic.get(x, (None,None,None))[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66422bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "il6= il6[il6.ref_bim.notna()]\n",
    "il6 = il6.merge(frq_data, on ='ID')\n",
    "for index, row in il6.iterrows():\n",
    "    if ((row['effect_allele'],row['other_allele'])==(row['ALT'], row['REF'])): \n",
    "        il6.at[index,'MAF'] = row['ALT_FREQS']\n",
    "        il6.at[index, 'BETA'] = row['beta']\n",
    "    elif ((row['effect_allele'],row['other_allele'])==(row['REF'], row['ALT'])):\n",
    "        il6.at[index,'MAF'] = 1- row['ALT_FREQS']\n",
    "        il6.at[index,'BETA'] = -row['beta']\n",
    "il6[['N']] = 575531\n",
    "st_il6 = il6[['ID','alt_bim','ref_bim','MAF','BETA','standard_error','p_value','N']]\n",
    "st_il6= st_il6.rename(columns={'ID':'SNP','standard_error':'SE','alt_bim':'A1','ref_bim':'A2','p_value':'P',\n",
    "                              'MAF':'EAF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dacf605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read bim file for harmonization\n",
    "bim_file = pd.read_table('../sharepro_analysis/region_chr7_22466819_23071617.bim',header=None)\n",
    "bim_file.columns = ['chr','ID','un','position','ALT','REF']\n",
    "bim_file['chr_pos'] = bim_file.chr.astype(str) + '_'+ bim_file.position.astype(str)\n",
    "bim_file = bim_file.drop_duplicates('position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f319e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def intersect_by_bim(df1, df2, bim_dict):\n",
    "    \"\"\"\n",
    "    Intersect two harmonised summary stats dataframes by SNPs present in a BIM dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        df1 (pd.DataFrame): First summary stats dataframe (IL6).\n",
    "        df2 (pd.DataFrame): Second summary stats dataframe (e.g., outcome).\n",
    "        bim_dict (dict): Dictionary with SNPs (keys) to restrict intersection.\n",
    "\n",
    "    Returns:\n",
    "        df1_sub (pd.DataFrame), df2_sub (pd.DataFrame): Subsetted dataframes.\n",
    "    \"\"\"\n",
    "    df1 = copy.deepcopy(df1)\n",
    "\n",
    "    common_snps = set(df1.SNP) & set(df2.SNP)\n",
    "    common_snps_filtered = [snp for snp in bim_dict.keys() if snp in common_snps]\n",
    "\n",
    "    df1_sub = df1[df1['SNP'].isin(common_snps_filtered)].reset_index(drop=True)\n",
    "    df2_sub = df2[df2['SNP'].isin(common_snps_filtered)].reset_index(drop=True)\n",
    "    \n",
    "    df1_sub.sort_values(by=\"SNP\", key=lambda column: column.map(lambda e: common_snps_filtered.index(e)), inplace=True)\n",
    "    df2_sub.sort_values(by=\"SNP\", key=lambda column: column.map(lambda e: common_snps_filtered.index(e)), inplace=True)\n",
    "\n",
    "\n",
    "    return df1_sub, df2_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c76921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def run_pwcoco_pipeline(\n",
    "    exposure_df,\n",
    "    bim_file,\n",
    "    bim_dict,\n",
    "    outcomes_info: list,\n",
    "    output_dir: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Run harmonisation and intersection for multiple outcome files, saving results to a common directory.\n",
    "\n",
    "    Parameters:\n",
    "        exposure_df (pd.DataFrame): The IL6 (exposure) dataframe.\n",
    "        bim_file (pd.DataFrame): BIM file dataframe.\n",
    "        bim_dict (dict): Dictionary of SNPs from BIM.\n",
    "        outcomes_info (list of dict): Each dict should contain:\n",
    "            - 'path': path to outcome summary stats\n",
    "            - 'n_cases': int\n",
    "            - 'n_controls': int\n",
    "            - 'has_rsid': bool\n",
    "            - 'colnames': dict with column names\n",
    "            - 'label': short label for output file naming\n",
    "        output_dir (str): Directory where outputs will be saved.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for outcome in outcomes_info:\n",
    "        print(f\"Processing: {outcome['label']}\")\n",
    "\n",
    "        formatted_outcome = harmonise_and_format(\n",
    "            sumstat=outcome['path'],\n",
    "            bim_file=bim_file,\n",
    "            has_rsid=outcome.get('has_rsid', True),\n",
    "            n_cases=outcome['n_cases'],\n",
    "            n_controls=outcome['n_controls'],\n",
    "            **outcome.get('colnames', {})\n",
    "        )\n",
    "\n",
    "        st_exp, st_out = intersect_by_bim(exposure_df, formatted_outcome, bim_dict)\n",
    "\n",
    "        st_exp.to_csv(os.path.join(output_dir, f\"IL6_{outcome['label']}.pwcoco\"), sep=\"\\t\", index=False)\n",
    "        st_out.to_csv(os.path.join(output_dir, f\"{outcome['label']}.pwcoco\"), sep=\"\\t\", index=False)\n",
    "        st_exp[['SNP']].to_csv(os.path.join(output_dir, f\"IL6_{outcome['label']}_forLD.txt\"), sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6a3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_info = [\n",
    "    {\n",
    "        'path': '../summ_stats/LAS.tsv.gz',\n",
    "        'n_cases': 9219,\n",
    "        'n_controls': 1503898,\n",
    "        'has_rsid': False,\n",
    "        'label': 'LAS',\n",
    "    },\n",
    "    {\n",
    "        'path': '../summ_stats/CAD_chr7_GCST90132315.tsv',\n",
    "        'n_cases': 210842,\n",
    "        'n_controls': 1167328,\n",
    "        'has_rsid': False,\n",
    "        'label': 'CAD',\n",
    "        'colnames': {\n",
    "            'effect_allele': 'effect_allele',\n",
    "            'other_allele': 'other_allele',\n",
    "            'eaf': 'effect_allele_frequency',\n",
    "            'beta': 'beta',\n",
    "            'se': 'standard_error',\n",
    "            'bp': 'base_pair_location',\n",
    "            'chromosome': 'chromosome',\n",
    "            'pval': 'p_value'\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'path': '../summ_stats/IS_GCST90104535_buildGRCh37.tsv.gz',\n",
    "        'n_cases': 86668,\n",
    "        'n_controls': 1503898,\n",
    "        'has_rsid': False,\n",
    "        'label': 'IS'\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'path': '../summ_stats/PAD.csv',\n",
    "        'n_cases': 31307,\n",
    "        'n_controls': 211753,\n",
    "        'has_rsid': True,\n",
    "        'label': 'PAD',\n",
    "        'colnames': {'rs_id':'SNP',\n",
    "            'effect_allele': 'effect_allele.outcome',\n",
    "            'other_allele': 'other_allele.outcome',\n",
    "            'eaf': 'eaf.outcome',\n",
    "            'beta': 'beta.outcome',\n",
    "            'se': 'se.outcome',\n",
    "            'bp': 'pos.outcome',\n",
    "            'chromosome': 'chr.outcome',\n",
    "            'pval': 'pval.outcome'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'path': '../summ_stats/plaque.tsv',\n",
    "        'n_cases': 21540,\n",
    "        'n_controls': 26894,\n",
    "        'has_rsid': True,\n",
    "        'label': 'PL',\n",
    "        'colnames': {'rs_id':'rs_id'}\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'path': '../summ_stats/RA_processed.tsv',\n",
    "        'n_cases': 35871,\n",
    "        'n_controls': 240149,\n",
    "        'has_rsid': True,\n",
    "        'label': 'RA',\n",
    "        'colnames': {'rs_id':'ID',\n",
    "            'eaf': 'effect_allele_frequency',\n",
    "            'se': 'standard_error',\n",
    "            'bp': 'position',\n",
    "            'chromosome': 'chr',\n",
    "            'pval': 'p_value'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'path': '../summ_stats/Meta_PMR_chr7.tsv',\n",
    "        'n_cases': 8156,\n",
    "        'n_controls': 416495,\n",
    "        'has_rsid': True,\n",
    "        'label': 'PMR',\n",
    "        'colnames': {'rs_id':'SNP',\n",
    "            'effect_allele': 'EA',\n",
    "            'other_allele': 'NEA',\n",
    "            'eaf': 'EAF',\n",
    "            'beta': 'Beta',\n",
    "            'se': 'StdErr',\n",
    "            'bp': 'position',\n",
    "            'chromosome': 'chr',\n",
    "            'pval': 'Pvalue'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b8c7063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: LAS\n",
      "Processing: CAD\n",
      "Processing: IS\n",
      "Processing: PAD\n",
      "Processing: PL\n",
      "Processing: RA\n",
      "Processing: PMR\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"pwcoco_outputs\"\n",
    "run_pwcoco_pipeline(st_il6, bim_file, bim_dic, outcomes_info, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc729a",
   "metadata": {},
   "source": [
    "## Preprare an LD matrix for every outcome using: \n",
    "\n",
    "#### plink --bfile region_chr7_22466819_23071617 --extract IL6_{outcome}_forLD.txt \\\n",
    "#### --matrix --out IL6_{outcome}_LD --r --write-snplist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36adac8",
   "metadata": {},
   "source": [
    "it will generate a file 'IL6_{outcome}_LD.ld' which should be passed to sharepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ef443aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed for CAD\n",
      "Executed for IS\n",
      "Executed for LAS\n",
      "Executed for PAD\n",
      "Executed for PL\n",
      "Executed for PMR\n",
      "Executed for RA\n"
     ]
    }
   ],
   "source": [
    "# List of outcome names\n",
    "names = ['CAD', 'IS', 'LAS', 'PAD', 'PL', 'PMR', 'RA']\n",
    "\n",
    "for name in names:\n",
    "    # run sharepro coloc\n",
    "    command = f\"python ~/projects/SharePro_coloc/src/SharePro/sharepro_coloc.py --z pwcoco_outputs/IL6_{name}.pwcoco pwcoco_outputs/{name}.pwcoco --ld /Users/a1/projects/IL6_pertrubation_coloc/sharepro_analysis/IL6_{name}_LD.ld --save results_test/resIL6_{name}\"\n",
    "\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "    print(f\"Executed for {name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
